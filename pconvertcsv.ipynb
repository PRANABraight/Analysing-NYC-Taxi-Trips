{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Parquet file\n",
    "parquet_file_path = 'yellow_tripdata_2024-09.parquet'\n",
    "data = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "# Convert to CSV\n",
    "csv_file_path = 'converted.csv'\n",
    "data.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f'Parquet file {parquet_file_path} has been converted to CSV file {csv_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    hour  avg_trip_distance  std_trip_distance  avg_fare_amount  \\\n",
      "0      0           3.829432           4.810559        19.479443   \n",
      "1      1           3.264212           4.086253        17.050060   \n",
      "2      2           2.802090           3.161652        15.312117   \n",
      "3      3           3.113981           3.606497        16.332604   \n",
      "4      4           4.477261           5.227941        21.843241   \n",
      "5      5           6.277956           6.778040        27.809795   \n",
      "6      6           4.928898           6.053218        22.858763   \n",
      "7      7           3.780577          19.383750        19.621207   \n",
      "8      8           3.257333           4.381644        19.064726   \n",
      "9      9           3.159940           4.803094        18.927381   \n",
      "10    10           3.197848          15.903750        19.211199   \n",
      "11    11           3.257084          14.373061        19.875650   \n",
      "12    12           3.279821           4.532224        20.255782   \n",
      "13    13           3.562750           4.928625        21.148435   \n",
      "14    14           3.741313          13.369412        21.922259   \n",
      "15    15           3.652506          13.165769        21.787662   \n",
      "16    16           3.706340           5.140139        22.034680   \n",
      "17    17           3.328960           4.679917        20.310954   \n",
      "18    18           3.168217           7.312560        19.021750   \n",
      "19    19           3.337014           4.638643        19.048224   \n",
      "20    20           3.577420          19.902521        19.256375   \n",
      "21    21           3.674476          14.937929        19.460519   \n",
      "22    22           3.811426           4.755089        20.044670   \n",
      "23    23           4.161165           5.064186        20.967398   \n",
      "\n",
      "    std_fare_amount  num_trips  \n",
      "0         22.089386      90719  \n",
      "1         18.959202      57819  \n",
      "2         16.854724      38849  \n",
      "3         17.543626      24562  \n",
      "4         24.528046      15493  \n",
      "5         28.434296      17455  \n",
      "6         25.484198      41241  \n",
      "7         20.941311      82527  \n",
      "8         18.731480     111990  \n",
      "9         18.439132     129678  \n",
      "10        18.274528     142711  \n",
      "11        19.767415     154867  \n",
      "12        19.761617     166915  \n",
      "13        21.189854     174310  \n",
      "14        22.611677     188571  \n",
      "15        22.430663     195546  \n",
      "16        22.705000     198018  \n",
      "17        20.916889     210672  \n",
      "18        19.983066     219026  \n",
      "19        20.016811     199784  \n",
      "20        20.038085     182411  \n",
      "21        20.323854     178428  \n",
      "22        21.014647     162792  \n",
      "23        22.031173     125951  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('converted.csv') \n",
    "\n",
    "# Convert 'tpep_pickup_datetime' to datetime\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "\n",
    "# Extract hour\n",
    "df['hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Group by hour and calculate summary statistics\n",
    "hourly_stats = df.groupby('hour').agg({\n",
    "    'trip_distance': ['mean', 'std'],\n",
    "    'fare_amount': ['mean', 'std'],\n",
    "    'passenger_count': 'count' \n",
    "})\n",
    "\n",
    "# Flatten the multi-index\n",
    "hourly_stats.columns = ['_'.join(col) for col in hourly_stats.columns]\n",
    "\n",
    "# Rename columns for clarity\n",
    "hourly_stats.rename(columns={\n",
    "    'trip_distance_mean': 'avg_trip_distance',\n",
    "    'trip_distance_std': 'std_trip_distance',\n",
    "    'fare_amount_mean': 'avg_fare_amount',\n",
    "    'fare_amount_std': 'std_fare_amount',\n",
    "    'passenger_count_count': 'num_trips'\n",
    "}, inplace=True)\n",
    "\n",
    "# Reset index to create a DataFrame\n",
    "hourly_stats = hourly_stats.reset_index()\n",
    "\n",
    "# Print the reduced dataset\n",
    "print(hourly_stats)\n",
    "\n",
    "# Save the reduced dataset to a CSV file\n",
    "hourly_stats.to_csv('hourly_taxi_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trips per Day:\n",
      " date\n",
      "2008-12-31         2\n",
      "2009-01-01         1\n",
      "2024-08-31        31\n",
      "2024-09-01     76209\n",
      "2024-09-02     69557\n",
      "2024-09-03     95511\n",
      "2024-09-04    108387\n",
      "2024-09-05    115881\n",
      "2024-09-06    111079\n",
      "2024-09-07    105894\n",
      "2024-09-08     93413\n",
      "2024-09-09     97101\n",
      "2024-09-10    106257\n",
      "2024-09-11    106904\n",
      "2024-09-12    120562\n",
      "2024-09-13    108343\n",
      "2024-09-14    107278\n",
      "2024-09-15     91059\n",
      "2024-09-16     96311\n",
      "2024-09-17    112977\n",
      "2024-09-18    118296\n",
      "2024-09-19    122219\n",
      "2024-09-20    115231\n",
      "2024-09-21    112921\n",
      "2024-09-22     99575\n",
      "2024-09-23     99121\n",
      "2024-09-24    102590\n",
      "2024-09-25    109381\n",
      "2024-09-26    118179\n",
      "2024-09-27    110974\n",
      "2024-09-28    120794\n",
      "2024-09-29     99415\n",
      "2024-09-30     58873\n",
      "2024-10-01         9\n",
      "Name: num_trips, dtype: int64\n",
      "\n",
      "Hourly and Daily Statistics:\n",
      "          date  avg_fare_amount_0  avg_fare_amount_1  avg_fare_amount_2  \\\n",
      "0  2008-12-31                NaN                NaN                NaN   \n",
      "1  2009-01-01                NaN                NaN                NaN   \n",
      "2  2024-08-31                NaN                NaN                NaN   \n",
      "3  2024-09-01          19.511124          16.903949          15.735516   \n",
      "4  2024-09-02          23.764968          21.071669          21.681507   \n",
      "\n",
      "   avg_fare_amount_3  avg_fare_amount_4  avg_fare_amount_5  avg_fare_amount_6  \\\n",
      "0                NaN                NaN                NaN                NaN   \n",
      "1                NaN                NaN                NaN                NaN   \n",
      "2                NaN                NaN                NaN                NaN   \n",
      "3          15.792783          19.200000          30.120170          29.536608   \n",
      "4          18.024153          28.287724          34.853226          34.147506   \n",
      "\n",
      "   avg_fare_amount_7  avg_fare_amount_8  ...  std_trip_distance_14  \\\n",
      "0                NaN                NaN  ...                   NaN   \n",
      "1                NaN                NaN  ...                   NaN   \n",
      "2                NaN                NaN  ...                   NaN   \n",
      "3          25.183071          23.538094  ...              5.789747   \n",
      "4          29.405998          25.329023  ...              5.919370   \n",
      "\n",
      "   std_trip_distance_15  std_trip_distance_16  std_trip_distance_17  \\\n",
      "0                   NaN                   NaN                   NaN   \n",
      "1                   NaN                   NaN                   NaN   \n",
      "2                   NaN                   NaN                   NaN   \n",
      "3              5.393866              5.620143              5.329462   \n",
      "4              5.792677              5.686475              6.041574   \n",
      "\n",
      "   std_trip_distance_18  std_trip_distance_19  std_trip_distance_20  \\\n",
      "0                   NaN                   NaN                   NaN   \n",
      "1                   NaN                   NaN                   NaN   \n",
      "2                   NaN                   NaN                   NaN   \n",
      "3              5.401016              5.315448              5.260443   \n",
      "4              5.391147              5.821058              5.776062   \n",
      "\n",
      "   std_trip_distance_21  std_trip_distance_22  std_trip_distance_23  \n",
      "0                   NaN                   NaN             12.126881  \n",
      "1                   NaN                   NaN                   NaN  \n",
      "2                   NaN                   NaN              5.737417  \n",
      "3              5.521742              5.646053              5.890978  \n",
      "4              6.703823              6.329101              6.483547  \n",
      "\n",
      "[5 rows x 121 columns]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'hourly_daily_taxi_stats.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHourly and Daily Statistics:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, pivoted_data\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Save the reduced dataset to a CSV file\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[43mpivoted_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhourly_daily_taxi_stats.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prana\\OneDrive\\Desktop\\llm\\Launchpad\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prana\\OneDrive\\Desktop\\llm\\Launchpad\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prana\\OneDrive\\Desktop\\llm\\Launchpad\\venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\prana\\OneDrive\\Desktop\\llm\\Launchpad\\venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\prana\\OneDrive\\Desktop\\llm\\Launchpad\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'hourly_daily_taxi_stats.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original taxi trip data \n",
    "df = pd.read_csv('converted.csv') \n",
    "\n",
    "# Convert 'tpep_pickup_datetime' to datetime\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "\n",
    "# Extract hour\n",
    "df['hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Extract date\n",
    "df['date'] = df['tpep_pickup_datetime'].dt.date\n",
    "\n",
    "# Group by hour and date\n",
    "hourly_daily_stats = df.groupby(['hour', 'date']).agg({\n",
    "    'trip_distance': ['mean', 'std'],\n",
    "    'fare_amount': ['mean', 'std'],\n",
    "    'passenger_count': 'count' \n",
    "})\n",
    "\n",
    "# Flatten multi-index and rename columns\n",
    "hourly_daily_stats.columns = ['_'.join(map(str, col)) for col in hourly_daily_stats.columns]\n",
    "hourly_daily_stats.rename(columns={\n",
    "    'trip_distance_mean': 'avg_trip_distance',\n",
    "    'trip_distance_std': 'std_trip_distance',\n",
    "    'fare_amount_mean': 'avg_fare_amount',\n",
    "    'fare_amount_std': 'std_fare_amount',\n",
    "    'passenger_count_count': 'num_trips'\n",
    "}, inplace=True)\n",
    "\n",
    "# Calculate total trips per day\n",
    "daily_trip_count = hourly_daily_stats.groupby('date')['num_trips'].sum()\n",
    "\n",
    "# Print the total trips per day\n",
    "print(\"Total Trips per Day:\\n\", daily_trip_count)\n",
    "\n",
    "# Pivot the DataFrame to have hours as columns and dates as rows\n",
    "pivoted_data = hourly_daily_stats.pivot_table(index='date', columns='hour')\n",
    "\n",
    "# Flatten the multi-index of the pivoted DataFrame\n",
    "pivoted_data.columns = ['_'.join(map(str, col)) for col in pivoted_data.columns]\n",
    "\n",
    "# Reset index to create a regular DataFrame\n",
    "pivoted_data = pivoted_data.reset_index()\n",
    "\n",
    "# Print the first few rows of the reduced dataset\n",
    "print(\"\\nHourly and Daily Statistics:\\n\", pivoted_data.head())\n",
    "\n",
    "# Save the reduced dataset to a CSV file\n",
    "pivoted_data.to_csv('hourly_daily_taxi_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2024-09-14 00:30:01   2024-09-14 00:49:09              2.0   \n",
      "1         2  2024-09-27 00:10:56   2024-09-27 00:30:35              1.0   \n",
      "2         2  2024-09-01 00:28:56   2024-09-01 00:36:44              2.0   \n",
      "3         2  2024-09-14 00:50:27   2024-09-14 01:01:49              1.0   \n",
      "4         2  2024-09-11 00:44:51   2024-09-11 00:51:55              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           1.94         1.0                  N           249           224   \n",
      "1           2.20         1.0                  N            48           158   \n",
      "2           1.16         1.0                  N           249           144   \n",
      "3           3.14         1.0                  N           113           140   \n",
      "4           0.82         1.0                  N           231           261   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             1         17.0    1.0      0.5        2.00           0.0   \n",
      "1             1         19.1    1.0      0.5        4.82           0.0   \n",
      "2             1          9.3    1.0      0.5        1.00           0.0   \n",
      "3             1         14.9    1.0      0.5        3.98           0.0   \n",
      "4             1          8.6    1.0      0.5        0.00           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \\\n",
      "0                    1.0         24.00                   2.5          0.0   \n",
      "1                    1.0         28.92                   2.5          0.0   \n",
      "2                    1.0         15.30                   2.5          0.0   \n",
      "3                    1.0         23.88                   2.5          0.0   \n",
      "4                    1.0         13.60                   2.5          0.0   \n",
      "\n",
      "   pickup_hour  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"converted.csv\")\n",
    "\n",
    "# Ensure you have a datetime column\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "\n",
    "# Extract the hour\n",
    "df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "# Calculate total trips\n",
    "total_trips = len(df)\n",
    "\n",
    "sampled_df = pd.DataFrame()\n",
    "for hour in range(24):\n",
    "    hour_df = df[df['pickup_hour'] == hour]\n",
    "    hour_trips = len(hour_df)\n",
    "    \n",
    "    if hour_trips > 0: # Avoid division by zero\n",
    "        sample_size = int(round((hour_trips / total_trips) * 1000))\n",
    "        \n",
    "        # Ensure sample size doesn't exceed the number of trips in the hour\n",
    "        sample_size = min(sample_size, hour_trips)\n",
    "        \n",
    "        if sample_size > 0:\n",
    "            sampled_hour_df = hour_df.sample(n=sample_size, replace=False, random_state=42) # Set random_state for reproducibility\n",
    "            sampled_df = pd.concat([sampled_df, sampled_hour_df])\n",
    "\n",
    "# Reset index\n",
    "sampled_df = sampled_df.reset_index(drop=True)\n",
    "print(len(sampled_df))\n",
    "print(sampled_df.head())\n",
    "# Save the sampled data\n",
    "sampled_df.to_csv(\"sampled_taxi_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_4272\\1355057763.py:28: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(['pickup_date', 'pickup_hour']).apply(sample_group).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in original data: 3110335\n",
      "Number of rows in sampled data: 138096\n",
      "First few rows of the sampled data:\n",
      "  pickup_date  pickup_hour  VendorID tpep_pickup_datetime  \\\n",
      "0  2008-12-31            0       NaN                  NaT   \n",
      "1  2008-12-31            1       NaN                  NaT   \n",
      "2  2008-12-31            2       NaN                  NaT   \n",
      "3  2008-12-31            3       NaN                  NaT   \n",
      "4  2008-12-31            4       NaN                  NaT   \n",
      "\n",
      "  tpep_dropoff_datetime  passenger_count  trip_distance  RatecodeID  \\\n",
      "0                   NaN              NaN            NaN         NaN   \n",
      "1                   NaN              NaN            NaN         NaN   \n",
      "2                   NaN              NaN            NaN         NaN   \n",
      "3                   NaN              NaN            NaN         NaN   \n",
      "4                   NaN              NaN            NaN         NaN   \n",
      "\n",
      "  store_and_fwd_flag  PULocationID  ...  payment_type  fare_amount  extra  \\\n",
      "0                NaN           NaN  ...           NaN          NaN    NaN   \n",
      "1                NaN           NaN  ...           NaN          NaN    NaN   \n",
      "2                NaN           NaN  ...           NaN          NaN    NaN   \n",
      "3                NaN           NaN  ...           NaN          NaN    NaN   \n",
      "4                NaN           NaN  ...           NaN          NaN    NaN   \n",
      "\n",
      "   mta_tax  tip_amount  tolls_amount  improvement_surcharge  total_amount  \\\n",
      "0      NaN         NaN           NaN                    NaN           NaN   \n",
      "1      NaN         NaN           NaN                    NaN           NaN   \n",
      "2      NaN         NaN           NaN                    NaN           NaN   \n",
      "3      NaN         NaN           NaN                    NaN           NaN   \n",
      "4      NaN         NaN           NaN                    NaN           NaN   \n",
      "\n",
      "   congestion_surcharge  Airport_fee  \n",
      "0                   NaN          NaN  \n",
      "1                   NaN          NaN  \n",
      "2                   NaN          NaN  \n",
      "3                   NaN          NaN  \n",
      "4                   NaN          NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Sampled data saved to sampled_hourly_daily_taxi_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # Load your data\n",
    "    df = pd.read_csv(\"converted.csv\")\n",
    "\n",
    "    # Convert pickup datetime to datetime objects (handle potential errors)\n",
    "    try:\n",
    "        df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    except KeyError:\n",
    "        print(\"Error: 'tpep_pickup_datetime' column not found. Check your data.\")\n",
    "        exit()\n",
    "    except ValueError:\n",
    "        print(\"Error: Could not parse 'tpep_pickup_datetime'. Check the format.\")\n",
    "        exit()\n",
    "\n",
    "    # Extract date and hour\n",
    "    df['pickup_date'] = df['tpep_pickup_datetime'].dt.date\n",
    "    df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "\n",
    "    def sample_group(group):\n",
    "        if not group.empty:\n",
    "            return group.sample(n=min(1, len(group)), replace=False, random_state=42)  # Sample min 1 and max all\n",
    "        return pd.DataFrame()  # Return empty DataFrame if group is empty\n",
    "\n",
    "    # Group by date and hour and apply the sampling function\n",
    "    sampled_df = df.groupby(['pickup_date', 'pickup_hour']).apply(sample_group).reset_index(drop=True)\n",
    "\n",
    "    # Ensure all date-hour combinations are present (even if no trips)\n",
    "    start_date = df['pickup_date'].min()\n",
    "    end_date = df['pickup_date'].max()\n",
    "    all_dates = pd.date_range(start=start_date, end=end_date).date\n",
    "\n",
    "    all_combinations = pd.DataFrame([(date, hour) for date in all_dates for hour in range(24)], columns=['pickup_date', 'pickup_hour'])\n",
    "\n",
    "    # Merge with all combinations to include missing ones. How='outer' to ensure all rows from both are included\n",
    "    sampled_df = pd.merge(all_combinations, sampled_df, on=['pickup_date', 'pickup_hour'], how='outer')\n",
    "\n",
    "    print(f\"Number of rows in original data: {len(df)}\")\n",
    "    print(f\"Number of rows in sampled data: {len(sampled_df)}\")\n",
    "    print(\"First few rows of the sampled data:\")\n",
    "    print(sampled_df.head())\n",
    "\n",
    "    # Save the sampled data\n",
    "    sampled_df.to_csv(\"test.csv\", index=False)\n",
    "    print(\"Sampled data saved to sampled_hourly_daily_taxi_data.csv\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'your_taxi_data.csv' not found. Check the file path.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
